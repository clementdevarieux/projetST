# -*- coding: utf-8 -*-
"""SparkStreamingModel2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KE2w-3dwAop1gSq85Y9AQzTQJ2n65qoK
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import pickle

"""***CHARGEMENT DES DONNÉES pour l'année 2022, 2021 et 2020***"""

# Chargement des données sur l'année 2022, 2021 et 2020 seulement

data_2022 = pd.read_csv('/content/sample_data/eco2mix-regional-cons-def-2.csv', delimiter=';')
data_2021 = pd.read_csv('/content/sample_data/eco2mix-regional-cons-def-3.csv', delimiter=';')
data_2020 = pd.read_csv('/content/sample_data/eco2mix-regional-cons-def-4.csv', delimiter=';')
data = pd.concat([data_2020, data_2021, data_2022])

"""***DATA PROCESSING 1***"""

# On recrée la colonne 'Date - Heure'
data['Date - Heure'] = pd.to_datetime(data['Date'] + ' ' + data['Heure'], errors='coerce')

# On défini 'Date - Heure' comme l'index
data = data.set_index('Date - Heure')

# Extraction des caractéristiques temporelles
data['year'] = data.index.year
data['month'] = data.index.month
data['day'] = data.index.day
data['hour'] = data.index.hour
data['day_of_week'] = data.index.dayofweek

"""***DATA PROCESSING 2***"""

# On supprime les colonnes 'Région', 'Nature', 'Date', 'Heure' et 'Column 30'
# (column 30 est vide et on a reconstitué les données temporelles donc on peut supprimer Date et Heure)
data = data.drop(columns=['Région', 'Nature','Date', 'Heure', 'Column 30'])

# Check sur les colonnes avec des valeurs manquantes
missing_values = data.isnull().sum()
print("Valeurs manquantes:\n", missing_values[missing_values > 0])

# Remplissage avec la médiane pour les colonnes numériques
data = data.apply(lambda x: x.fillna(x.median()), axis=0)

# On vérifie s'il n'y a plus de valeurs manquantes
missing_values_after = data.isnull().sum()
print("Valeurs manquantes:\n", missing_values_after[missing_values_after > 0])

assert data.isnull().sum().sum() == 0, "Il reste des valeurs manquantes"

"""***SÉPARATION DES DONNÉES DE TRAINING ET TEST***"""

# Séparation des données de training et de test
# Je prend 126000 lignes de test parce que c'est 20% de la totalité de nos données, pour évaluer notre modèle sur des données qu'il n'a jamais vu
test_size = 126000
test_indices = data.sample(n=test_size).index
train_indices = data.index.difference(test_indices)

X_train = data.loc[train_indices].drop(columns=['Consommation (MW)'])
y_train = data.loc[train_indices]['Consommation (MW)']

X_test = data.loc[test_indices].drop(columns=['Consommation (MW)'])
y_test = data.loc[test_indices]['Consommation (MW)']

"""***TRAINING AVEC UN RANDOM FOREST***"""

# Entraînement du Random Forest
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

"""***TEST PRÉDICTION***"""

# Prédiction
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# Évaluation
mae_train = mean_absolute_error(y_train, y_train_pred)
mse_train = mean_squared_error(y_train, y_train_pred)
r2_train = r2_score(y_train, y_train_pred)

mae_test = mean_absolute_error(y_test, y_test_pred)
mse_test = mean_squared_error(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

print(f'Training MAE: {mae_train}')
print(f'Training MSE: {mse_train}')
print(f'Training R^2: {r2_train}')

print(f'Test MAE: {mae_test}')
print(f'Test MSE: {mse_test}')
print(f'Test R^2: {r2_test}')

"""***VISUALISATION DU TRAINING ET DU TEST***"""

# Visualisation pour le training et le test
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.3)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--r')
plt.xlabel('Valeurs réelles')
plt.ylabel('Valeurs prédites')
plt.title('Ensemble d\'entraînement')
plt.grid(True)

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.3)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
plt.xlabel('Valeurs réelles')
plt.ylabel('Valeurs prédites')
plt.title('Ensemble de test')
plt.grid(True)

plt.tight_layout()
plt.show()

"""***PRÉPARATION DE LA FONCTION POUR LE JOUR DE PRÉDICTION***"""

# Fonction pour préparer les données pour le jour de prédiction
def prepare_features_for_future_date(year, month, day, X_train, code_insee):
    hours = list(range(24))  # 0 à 23 heures
    date_str = f"{year}-{month:02d}-{day:02d}"
    date_times = [f"{date_str} {hour:02d}:00:00" for hour in hours]
    date_times = pd.to_datetime(date_times)

    features = pd.DataFrame(index=date_times)
    features['year'] = features.index.year
    features['month'] = features.index.month
    features['day'] = features.index.day
    features['hour'] = features.index.hour
    features['day_of_week'] = features.index.dayofweek

    # On utilise les valeurs moyennes historiques pour les autres colonnes
    historical_means = X_train.mean()
    for column in X_train.columns:
        if column in features.columns:
            continue
        features[column] = historical_means[column]

    features['Code INSEE région'] = code_insee

    # On réordonne les colonnes
    features = features[X_train.columns]

    return features

"""***TEST POUR UN JOUR ET UNE RÉGION DONNÉS***"""

# On spécifie le jour et la région
year = 2023
month = 1
day = 17
# Ile de france
code_insee = 11

# Préparer les données pour cette date future et cette région
features = prepare_features_for_future_date(year, month, day, X_train, code_insee)

# Check des variables d'entrées
print(f"\nVariable d'entrée pour la prédiction pour le {day}/{month}/{year} et le Code INSEE {code_insee} :")
print(features.head(24))

# Prediction
hourly_predictions = model.predict(features)
total_prediction = hourly_predictions.sum()

# Affiche le résultat
print(f"Consommation totale prédite pour le {day}/{month}/{year} et le Code INSEE {code_insee} : {total_prediction:.2f}")

"""***Enregistre le model en format pickle ***"""

with open('random_forest_model.pkl', 'wb') as file:
    pickle.dump(model, file)

print("Modèle enregistré 'random_forest_model.pkl'")

"""***Load du model pour prediction ***"""

# Load le model
with open('random_forest_model.pkl', 'rb') as file:
    loaded_model = pickle.load(file)

features = prepare_features_for_future_date(year, month, day, X_train, code_insee)

# Prédiction
hourly_predictions_loaded_model = loaded_model.predict(features)
total_prediction_loaded_model = hourly_predictions_loaded_model.sum()

print(f"Consommation totale prédite pour le {day}/{month}/{year} et le Code INSEE {code_insee}: {total_prediction_loaded_model:.2f}")